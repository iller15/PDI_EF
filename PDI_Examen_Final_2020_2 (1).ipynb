{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peNv8JLDkSHF"
   },
   "source": [
    "# Procesamiento Digital de Imágenes - Examen Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWNjYh93k-Rw"
   },
   "source": [
    "## Instrucciones\n",
    "\n",
    "1.\tEl examen consta de 1 pregunta y tendrá 1 semana para resolverla con su equipo del trabajo final (en caso de sobrar uno o dos alumnos pueden crearse, máximo dos equipos de 2 integrantes).\n",
    "2.\tEl trabajo será entregado, en el aula virtual, hasta las 7:59:59 am del viernes 8 de diciembre. En seguida habrá una exposición, máximo 10 minutos por grupo, de los grupos de trabajo de 8 a 10 am. **BAJO NINGUN MOTIVO SE ACEPTARAN EXAMENES FUERA DEL LIMITE DE TIEMPO INDICADO**\n",
    "3.\tEl examen cuenta con un docente académico, el cual estará conectado durante los primeros 20 minutos del examen.\n",
    "4.\tLas dudas conceptuales sobre el examen han de presentarse dentro de los primeros 20 minutos mediante un correo al profesor GONZALEZ VALENZUELA, RICARDO EUGENIO a pcsirgon@upc.edu.pe.\n",
    "5.\tLos inconvenientes técnicos pueden presentarse a pasado los primeros 20 minutos, puede comunicarlo al profesor GONZALEZ VALENZUELA, RICARDO EUGENIO a pcsirgon@upc.edu.pe.\n",
    "6.\tEl profesor en mención solo recibirá correos provenientes de las cuentas UPC, de ninguna manera se recibirán correos de cuentas públicas. \n",
    "7.\tAnte problemas técnicos, debe de forma obligatoria adjuntar evidencias del mismo, como capturas de pantalla, videos, fotos, etc. Siendo requisito fundamental que, en cada evidencia se pueda apreciar claramente la fecha y hora del sistema operativo del computador donde el alumno está rindiendo el examen. \n",
    "8.\tLos correos sobre problemas técnicos se recibirán hasta 15 minutos luego de culminado el examen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77aKbY1YFl3g"
   },
   "source": [
    "## Integrantes\n",
    "\n",
    "*   Alumno 1: <font color='green'> u20181a010 - Joaquin Adrian Galvan Diaz</font><br>\n",
    "*   Alumno 2: <font color='green'> u201818067 - Dante Brandon Moreno Carhuacusma</font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLrugUgnlIMN"
   },
   "source": [
    "## Caso de Estudio - Video Summarization\n",
    "\n",
    "1. Descargar y/o crear videos de 10 a 15 minutos y efectuar un resumen de tiempo en los mismos.\n",
    "\n",
    "2. Aplicando únicamente técnicas de procesamiento digital de imágenes, segmentar los objetos que aparecen en diferentes instantes y sobreponerlos en una cantidad muy inferior de frames etiquetando cada objeto con los insantes de tiempo en que aparece en el video.\n",
    "\n",
    "3. En el siguiente [video](https://www.youtube.com/watch?v=gk3qTMlcadk), podrá tener un mejor concepto de lo solicitado. \n",
    "\n",
    "4.\tDocumente sus métodos y elecciones. Explique su metodología. Codifique su solución. Obtenga resultados y realice comparaciones. Redacte sus conclusiones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EIvisRJOJgJ_"
   },
   "source": [
    "## Resolución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r02P9REKJkS1"
   },
   "source": [
    "### Metodología (6 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYL90_sGsXQv"
   },
   "source": [
    "<font color='green'>Aquí **enumere** y **explique** los pasos de su metodología </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primer método: Diferencia de imágenes y ROIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En nuestro primer método, asumimos que el primer frame del video está \"limpio\", es decir, es la base sobre la cual detectar los nuevos objetos en la imagen. Definimos entonces:\n",
    "\n",
    " * $A$: Primer frame del video.\n",
    " * $B_{n}$: n-ésimo frame del video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primera tarea es identificar regiones de interés (ROIs) donde ocurran cambios en el video. Luego se podrá utilizar esta información para calcular juntar los objetos en el resumen. El algoritmo de es:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Por cada $B_{n}$:\n",
    "> $ROIs$: Arreglo que guardará las regiones de interés en el frame.\n",
    "> - 1.1. Hallar la diferencia: $D_{n}$ = $A$ - $B_{n}$. **Si** $B_{n}$ es similar a $A$, $D_{n}$ estará compuesto en su mayoría por $0s$.\n",
    "> - 1.2. Aplicar filtro de la media o mediana sobre $D_{n}$, ya que puede ser afectado por el rudio\n",
    "> - 1.3. Binarizar o Aplicar un operador clásico de Edge Detection sobre $D_{n}$\n",
    "> - 1.4. $contornos \\leftarrow findContours(D_{n})$\n",
    "> - 1.5. Por cada $c$ en $contornos$:\n",
    ">> * Agregar rectángulo envolvente de $c$ al arreglo $ROIs$\n",
    "\n",
    "> *TODO*: Mantener el mismo ID del objeto para los diferentes frames, quizá con un Match Template entre ROIs (?) o solo asumiendo que mientras los ROIS de $D_{n}$ y $D_{n+1}$ choquen, son el mismo objeto. Cuando el objeto \"salga\" de la pantalla, esa ROI debería volver a parecerse a A y convertirse en 0s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvNvTKIFJvwQ"
   },
   "source": [
    "### Implementación (6 puntos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pafy\n",
      "  Downloading pafy-0.5.5-py2.py3-none-any.whl (35 kB)\n",
      "Installing collected packages: pafy\n",
      "Successfully installed pafy-0.5.5\n",
      "Collecting youtube-dl\n",
      "  Downloading youtube_dl-2020.12.2-py2.py3-none-any.whl (1.8 MB)\n",
      "Installing collected packages: youtube-dl\n",
      "Successfully installed youtube-dl-2020.12.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pafy\n",
    "!pip install youtube-dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LQoyq0_GJ5aB"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pafy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargar el vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv2_imshow(imagen, titulo = \"Imagen\"):\n",
    "    cv2.imshow(titulo,imagen)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.youtube.com/watch?v=CkVJyAKwByw\"\n",
    "video = pafy.new(url)\n",
    "best = video.getbest(preftype=\"mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducir el video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture()\n",
    "capture.open(best.url)\n",
    "\n",
    "anterior = None\n",
    "start = True\n",
    "\n",
    "while (capture.isOpened()):\n",
    "    ##Por cada frame del video:\n",
    "    #capturar y mostrar el frame\n",
    "    ret, frame = capture.read()\n",
    "    #cv2.imshow(\"It's meta\",frame)\n",
    "    frame = cv2.cvtColor(frame,cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    if not start:        \n",
    "        dif = anterior - frame\n",
    "        dif = cv2.adaptiveThreshold(frame,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,11,0)\n",
    "        cv2.imshow(\"Diferencia\",dif)\n",
    "    else:\n",
    "        start = False    \n",
    "    anterior = frame\n",
    "\n",
    "    if(cv2.waitKey(20) & 0xFF == ord('q')):\n",
    "        anterior = dif\n",
    "        break\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imshow(\"Diferencia\",anterior)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas Dante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anterior.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficarRectDeROIs(imagen, ROIs):\n",
    "    for roi in ROIs:\n",
    "        (x,y,w,h) = roi\n",
    "        cv2.rectangle(imagen, (x,y), (x+w,y+h), (255,0,0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturar los primeros \"N\" frames para poder testear.\n",
    "Se baja la resolución para evitar carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Prueba = 240 #Cantidad de frames de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480 853\n"
     ]
    }
   ],
   "source": [
    "nH = int(anterior.shape[0] // 1.5)\n",
    "nW = int(anterior.shape[1] // 1.5)\n",
    "print(nH,nW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Captura los frames de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mB = [] # Milisegundos en los que se ubican los frames B_i\n",
    "B = [] # Frames de Prueba\n",
    "A = None # Frame Original\n",
    "capture.open(best.url)\n",
    "_, A = capture.read() #.......... Frame \"Original\", se asume que en este no hay \"objetos\" en pantalla\n",
    "A = cv2.cvtColor(A,cv2.COLOR_RGB2GRAY)\n",
    "nH = int(A.shape[0] // 1.5)\n",
    "nW = int(A.shape[1] // 1.5)\n",
    "A = cv2.resize(A, (nW,nH))\n",
    "for i in range(N_Prueba):\n",
    "    _, f = capture.read()\n",
    "    ms = capture.get(0) # Get los milisegundos\n",
    "    f = cv2.cvtColor(f,cv2.COLOR_RGB2GRAY)\n",
    "    f = cv2.resize(f, (nW,nH))\n",
    "    B.append(f)\n",
    "    mB.append(ms)\n",
    "capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "print(type(mB[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna un arreglos de ROIs de un frame n, comparando con el frame 0\n",
    "def roisDeFrame(f0, fn, dimKernelBlur, umbralDif): # BTW: dimKernelBlur debe ser impar\n",
    "    if len(f0.shape) > 2:\n",
    "        f0 = cv2.cvtColor(f0,cv2.COLOR_RGB2GRAY)\n",
    "    if len(fn.shape) > 2:\n",
    "        fn = cv2.cvtColor(fn,cv2.COLOR_RGB2GRAY)\n",
    "    D = f0 - fn\n",
    "    D = cv2.medianBlur(D,dimKernelBlur)\n",
    "    _, D = cv2.threshold(D,umbralDif,255,cv2.THRESH_BINARY)\n",
    "    contornos, _ = cv2.findContours(D,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    ROIs = []\n",
    "    for contorno in contornos:\n",
    "        x,y,w,h = cv2.boundingRect(contorno)\n",
    "        ROIs.append((x,y,w,h))\n",
    "    return ROIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Realización:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquí se realiza el cálculo:\n",
    "# \" *Vxp \" significa \"Experimentar con los valores\"\n",
    "arrROIs = []\n",
    "for b in B:\n",
    "    rois = roisDeFrame(A, b, 27, 180) # * Vxp, la dimensión debe ser impar\n",
    "    arrROIs.append(rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "capture.open(best.url)\n",
    "while(True):\n",
    "    _, frame = capture.read()\n",
    "    frame = cv2.resize(frame, (nW,nH)) #.... TODO: pasar ROI a la resolución original :c\n",
    "    if j < len(arrROIs):\n",
    "        graficarRectDeROIs(frame, arrROIs[j])\n",
    "    cv2.imshow(\"Diferencia\",frame)\n",
    "    j += 1\n",
    "    if(cv2.waitKey(20) & 0xFF == ord('q')):\n",
    "        break\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Material adicional:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* OpenCV Python Tutorials. *Getting started with videos*. Recuperado de: https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html\n",
    "* OpenCV. *Reading and writing images and video* Recuperado de: https://docs.opencv.org/2.4/modules/highgui/doc/reading_and_writing_images_and_video.html#videocapture-get "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pH7A73FhJ51o"
   },
   "source": [
    "### Resultados y Discusión (6 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWS0I-GXJ57i"
   },
   "source": [
    "<font color='green'> Discuta los **varios resultados obtenidos** por la selección de **diversos parámetros seleccionados** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jEyQ2THGJ6BA"
   },
   "source": [
    "### Conclusiones (2 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNOKEOoRJ6Ep"
   },
   "source": [
    "<font color='green'> Redacte, al menos, **5 conclusiones relevantes** referentes a como cubrió su objetivo y que le ayudó a optimizar sus resutlados. </font>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "PDI - Examen Final - 2020-2",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
