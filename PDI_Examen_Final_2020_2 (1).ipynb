{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peNv8JLDkSHF"
   },
   "source": [
    "# Procesamiento Digital de Imágenes - Examen Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWNjYh93k-Rw"
   },
   "source": [
    "## Instrucciones\n",
    "\n",
    "1.\tEl examen consta de 1 pregunta y tendrá 1 semana para resolverla con su equipo del trabajo final (en caso de sobrar uno o dos alumnos pueden crearse, máximo dos equipos de 2 integrantes).\n",
    "2.\tEl trabajo será entregado, en el aula virtual, hasta las 7:59:59 am del viernes 8 de diciembre. En seguida habrá una exposición, máximo 10 minutos por grupo, de los grupos de trabajo de 8 a 10 am. **BAJO NINGUN MOTIVO SE ACEPTARAN EXAMENES FUERA DEL LIMITE DE TIEMPO INDICADO**\n",
    "3.\tEl examen cuenta con un docente académico, el cual estará conectado durante los primeros 20 minutos del examen.\n",
    "4.\tLas dudas conceptuales sobre el examen han de presentarse dentro de los primeros 20 minutos mediante un correo al profesor GONZALEZ VALENZUELA, RICARDO EUGENIO a pcsirgon@upc.edu.pe.\n",
    "5.\tLos inconvenientes técnicos pueden presentarse a pasado los primeros 20 minutos, puede comunicarlo al profesor GONZALEZ VALENZUELA, RICARDO EUGENIO a pcsirgon@upc.edu.pe.\n",
    "6.\tEl profesor en mención solo recibirá correos provenientes de las cuentas UPC, de ninguna manera se recibirán correos de cuentas públicas. \n",
    "7.\tAnte problemas técnicos, debe de forma obligatoria adjuntar evidencias del mismo, como capturas de pantalla, videos, fotos, etc. Siendo requisito fundamental que, en cada evidencia se pueda apreciar claramente la fecha y hora del sistema operativo del computador donde el alumno está rindiendo el examen. \n",
    "8.\tLos correos sobre problemas técnicos se recibirán hasta 15 minutos luego de culminado el examen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77aKbY1YFl3g"
   },
   "source": [
    "## Integrantes\n",
    "\n",
    "*   Alumno 1: <font color='green'> u20181a010 - Joaquin Adrian Galvan Diaz</font><br>\n",
    "*   Alumno 2: <font color='green'> u201818067 - Dante Brandon Moreno Carhuacusma</font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLrugUgnlIMN"
   },
   "source": [
    "## Caso de Estudio - Video Summarization\n",
    "\n",
    "1. Descargar y/o crear videos de 10 a 15 minutos y efectuar un resumen de tiempo en los mismos.\n",
    "\n",
    "2. Aplicando únicamente técnicas de procesamiento digital de imágenes, segmentar los objetos que aparecen en diferentes instantes y sobreponerlos en una cantidad muy inferior de frames etiquetando cada objeto con los insantes de tiempo en que aparece en el video.\n",
    "\n",
    "3. En el siguiente [video](https://www.youtube.com/watch?v=gk3qTMlcadk), podrá tener un mejor concepto de lo solicitado. \n",
    "\n",
    "4.\tDocumente sus métodos y elecciones. Explique su metodología. Codifique su solución. Obtenga resultados y realice comparaciones. Redacte sus conclusiones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EIvisRJOJgJ_"
   },
   "source": [
    "## Resolución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r02P9REKJkS1"
   },
   "source": [
    "### Metodología (6 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Detección: Diferencia de imágenes y ROIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En nuestro primer método, asumimos que el primer frame del video está \"limpio\", es decir, es la base sobre la cual detectar los nuevos objetos en la imagen. Definimos entonces:\n",
    "\n",
    " * $A$: Primer frame del video.\n",
    " * $B_{n}$: n-ésimo frame del video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primera tarea es identificar regiones de interés (ROIs) donde ocurran cambios en el video. Luego se podrá utilizar esta información para calcular juntar los objetos en el resumen. El algoritmo de es:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Por cada $B_{n}$:\n",
    "> $ROIs$: Arreglo que guardará las regiones de interés en el frame.\n",
    "> - 1.1. Hallar la diferencia: $D_{n}$ = $A$ - $B_{n}$. **Si** $B_{n}$ es similar a $A$, $D_{n}$ estará compuesto en su mayoría por $0s$.\n",
    "> - 1.2. Aplicar filtro de la media o mediana sobre $D_{n}$, ya que puede ser afectado por el rudio\n",
    "> - 1.3. Binarizar o Aplicar un operador clásico de Edge Detection sobre $D_{n}$\n",
    "> - 1.4. $contornos \\leftarrow findContours(D_{n})$\n",
    "> - 1.5. Por cada $c$ en $contornos$:\n",
    ">> * Agregar rectángulo envolvente de $c$ al arreglo $ROIs$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El arreglo $ROIs$ guarda las regiones de interés en un frame detectadas. Para la selección, queremos guardar un identificador del objeto para los diferentes frames. Además, se debe guardar el momento en el tiempo en el que aparece una región de interés. Entonces, definimos \"Objeto\" en el video, donde cada \"Objeto\" aparece en distintas ROIs en cada frame del video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame de Objetos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder expresar que en el video esperamos varios objetos, donde cada uno ocupa diferentes áreas de la imagen en un frame (y segundo) diferente, trabajamos con un DataFrame de Objetos:\n",
    ">ID | ROI | Frame | Segundo\n",
    ">--- | --- | --- | ---\n",
    ">0 | (x, y, w, h) | $f_{0}$ | $t_{0}$\n",
    ">0 | (x, y, w, h) | $f_{1}$ | $t_{0}$\n",
    ">0 | (x, y, w, h) | $f_{2}$ | $t_{1}$\n",
    ">1 | (x, y, w, h) | $f_{1}$ | $t_{0}$\n",
    ">1 | (x, y, w, h) | $f_{2}$ | $t_{1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante la detección de $ROIs$, frame por frame, añadimos el arreglo al DataFrame, asignando un ID de objeto si es necesario, o creando un nuevo ID. Para lograr esto, nos apoyamos de la función:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$asignarObjetos(objetos, ROIs_{n}, n, segundo, umbralRatioArea):$\n",
    "> Donde:\n",
    "> * $objetos$: DataFrame de los objetos que aparecen en el **frame $n-1$**\n",
    "> * $ROIs_{n}$: Regiones de interés en el frame $n$\n",
    "> * $segundo$: Tiempo (en segundos) en el que se ubica el frame $f_n$\n",
    "> * $umbralRatioArea$: Umbral para determinar si dos regiones de interés son del mismo objeto\n",
    "> Definimos:\n",
    "> * agregados: Arreglo de filas por agregar al DataFrame en la función 'madre'.\n",
    "> 1. Por cada $objeto$ en $objetos$:\n",
    "> - 1.1. $ROI \\leftarrow ROI$ de $objeto$ \n",
    "> - 1.2. Por cada $ROI_t$ en $ROIs_{n}$ (las nuevas regiones de interés en el frame $n$):\n",
    ">> - a) $areaInterseccion \\leftarrow$ Área que intersecan $ROI$ y $ROI_t$\n",
    ">> - b) Si $\\frac{areaInterseccion}{areaROI}$ > $umbralRatioArea$ y $\\frac{areaInterseccion}{areaROI_t}$ > $umbralRatioArea$, es decir, si en ambas regiones la intersección ocupa una parte mayor al umbral: \n",
    ">>> - Añade [ID de $objeto$, $ROI_t$, $n$, $segundo$] al arreglo de $agregados$ \n",
    ">>> - Quita $ROI_t$ de $ROIs_n$, ya que no tiene que analizarlo porque ya se le asignó ID de objeto\n",
    "> Pueden haber sobrado regiones de interés, que asumimos son nuevos objetos en pantalla\n",
    "> * $nID \\leftarrow$ ID máximo en $objetos$ + 1, empezamos a enumerar desde este número para los nuevos objetos\n",
    "> 2. Por cada $ROI_t$ en $ROIs_{n}$:\n",
    "agregados.append([n_ID, roi_t, t_frame, mseg])\n",
    "        n_ID += 1\n",
    "    return agregados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Por cada frame $f_{n}$:\n",
    "> - Objetos: DataFrame que almacena los objetos detectados\n",
    "> - ... (Detección de regiones interés, explicada anteriormente)\n",
    "> - $ROIs$: Arreglo que guardará las regiones de interés en el frame $B_{n}$.\n",
    "> - $objetosPrevios:$ Arreglo que guarda solo los objetos del frame $f_{n-1}$.\n",
    "> - 1.1 $nuevasFilas \\leftarrow asignarObjetos(objetosPrevios, ROIs, n, ms,UmbralInterseccion)$.\n",
    "\n",
    "> El arreglo $nuevasFilas$ está en el formato [[ID 1, ROI 1, Frame 1, Segundo 1], [ID 2, ...], ...].\n",
    "    #---- nuevasFilas está en el formato, pero \"objetos\" puede aún ser nulo, así que valida:\n",
    "    nuevasFilas = pd.DataFrame(data=nuevasFilas,columns=[\"ID\",\"ROI\",\"Frame\",\"Segundo\"])\n",
    "    if len(objetos) > 0:\n",
    "        objetos = objetos.append(nuevasFilas,ignore_index=True) # ... Si ya existen objetos, añade los nuevos\n",
    "    else:\n",
    "        objetos = nuevasFilas #...................................... Si nunca hubieron, ahora hay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvNvTKIFJvwQ"
   },
   "source": [
    "### Implementación (6 puntos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pafy in c:\\users\\joaqu\\anaconda3\\lib\\site-packages (0.5.5)\n",
      "Requirement already satisfied: youtube-dl in c:\\users\\joaqu\\anaconda3\\lib\\site-packages (2020.11.29)\n"
     ]
    }
   ],
   "source": [
    "!pip install pafy\n",
    "!pip install youtube-dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "LQoyq0_GJ5aB"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pafy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargar el vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv2_imshow(imagen, titulo = \"Imagen\"):\n",
    "    cv2.imshow(titulo,imagen)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.youtube.com/watch?v=CkVJyAKwByw\"\n",
    "video = pafy.new(url)\n",
    "best = video.getbest(preftype=\"mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducir el video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Frame_Prueba_0 = None\n",
    "Frame_Prueba_X = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture()\n",
    "capture.open(best.url)\n",
    "\n",
    "j = 0\n",
    "\n",
    "anterior = None\n",
    "start = True\n",
    "\n",
    "while (capture.isOpened()):\n",
    "    ##Por cada frame del video:\n",
    "    #capturar y mostrar el frame\n",
    "    ret, frame = capture.read()\n",
    "    #cv2.imshow(\"It's meta\",frame)\n",
    "    frame = cv2.cvtColor(frame,cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    if j == 0:\n",
    "        Frame_Prueba_0 = frame\n",
    "    elif j == 180:\n",
    "        Frame_Prueba_X = frame\n",
    "    \n",
    "    if not start:        \n",
    "        dif = anterior - frame\n",
    "        dif = cv2.adaptiveThreshold(frame,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,11,0)\n",
    "        cv2.imshow(\"Diferencia\",dif)\n",
    "    else:\n",
    "        start = False    \n",
    "    anterior = frame\n",
    "    \n",
    "    j += 1\n",
    "    \n",
    "    if(cv2.waitKey(20) & 0xFF == ord('q')):\n",
    "        anterior = dif\n",
    "        break\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imshow(\"Diferencia\",anterior)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas Dante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anterior.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficarRectDeROIs(imagen, ROIs):\n",
    "    for roi in ROIs:\n",
    "        (x,y,w,h) = roi\n",
    "        cv2.rectangle(imagen, (x,y), (x+w,y+h), (255,0,0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturar los primeros \"N\" frames para poder testear.\n",
    "Se baja la resolución para evitar carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Prueba = 240 #Cantidad de frames de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480 853\n"
     ]
    }
   ],
   "source": [
    "nH = int(anterior.shape[0] // 1.5)\n",
    "nW = int(anterior.shape[1] // 1.5)\n",
    "print(nH,nW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones adicionales para ayudar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def areaInterseccion(roi1, roi2):\n",
    "    def dEje(tuplaS): #tuplaS: [ (x1, x1 + w1) , (x2, x2 + w2) ]\n",
    "        def auxResta(v1, v2): #.... Devuelve la resta, si es negativo, devuelve 0\n",
    "            d = v1 - v2\n",
    "            if d < 0:\n",
    "                return 0\n",
    "            return d\n",
    "        im = 0 #id del segmento más cerca a 0\n",
    "        iM = 1 #id del segmento más lejos de 0\n",
    "        if tuplaS[1][0] < tuplaS[0][0]:\n",
    "            im = 1\n",
    "            iM = 0\n",
    "        return (tuplaS[im][1] - tuplaS[iM][0]) - auxResta(tuplaS[im][1], tuplaS[iM][1])\n",
    "    (x1, y1, w1, h1) = roi1\n",
    "    (x2, y2, w2, h2) = roi2\n",
    "    if x1 < x2 + w2 and x1 + w1 > x2 and y1 < y2 + h2 and y1 + h1 > y2: # Si colisionan\n",
    "        dx = dEje([(x1, x1+w1), (x2, x2+w2)])\n",
    "        dy = dEje([(y1, y1+h1), (y2, y2+h2)])\n",
    "        return dx * dy\n",
    "    return 0\n",
    "def roiUroi(roi1, roi2):\n",
    "    nXmin = min(roi1[0],roi2[0])\n",
    "    nXmax = max(roi1[0] + roi1[2],roi2[0] + roi2[2])\n",
    "    nYmin = min(roi1[1],roi2[1])\n",
    "    nYmax = max(roi1[1] + roi1[3],roi2[1] + roi2[3])\n",
    "    return (nXmin, nYmin, nXmax - nXmin, nYmax - nYmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "areaInterseccion((0,0,3,3),(0,0,4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## =========================== LEER ========================\n",
    "# Se está agregando un limitador para no tener \"rois\" muy pequeñas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna un arreglos de ROIs de un frame n, comparando con el frame 0\n",
    "def roisDeFrame(f0, fn, dimKernelBlur, umbralDif): # BTW: dimKernelBlur debe ser impar\n",
    "    if len(f0.shape) > 2:\n",
    "        f0 = cv2.cvtColor(f0,cv2.COLOR_RGB2GRAY)\n",
    "    if len(fn.shape) > 2:\n",
    "        fn = cv2.cvtColor(fn,cv2.COLOR_RGB2GRAY)\n",
    "    f0 = np.array(f0, dtype=np.int16) #..... Permitir los valores negativos en la resta inicial :)\n",
    "    fn = np.array(fn, dtype=np.int16) #..... \"\"\n",
    "    D = np.array(np.abs(f0 - fn), dtype=np.uint8)\n",
    "    D = cv2.medianBlur(D,dimKernelBlur)\n",
    "    _, D = cv2.threshold(D,umbralDif,255,cv2.THRESH_BINARY)\n",
    "    contornos, _ = cv2.findContours(D,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    ROIs = []\n",
    "    for contorno in contornos:\n",
    "        x,y,w,h = cv2.boundingRect(contorno)\n",
    "        ROIs.append((x,y,w,h))\n",
    "    return ROIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruebas con dos frames del video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2_imshow(Frame_Prueba_0)\n",
    "cv2_imshow(Frame_Prueba_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "auxRois = roisDeFrame(Frame_Prueba_0, Frame_Prueba_X,13,110)\n",
    "print(len(auxRois))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asignarObjetos(objetos, rois_t, t_frame, mseg, umbralRatioAr):\n",
    "    # Comparamos los rois en un frame 't'con los rois asignados a objetos en el frame previo (cuando lo llaman debe validar eso)\n",
    "    # (Asume que debe haber continuidad, si un objeto sale de la pantalla y regresa, lo toma como otro)\n",
    "    # Utiliza un umbral de intersección para decidir si dos rois son del mismo objeto en diferentes frames\n",
    "    # RETORNA: arreglo de filas a agregar al DataFrame, con su ID de objeto, ROI, frame y segundo\n",
    "    agregados = []\n",
    "    for i in range(len(objetos)): #........ Por cada uno de los objetos en el frame t\n",
    "        objeto = objetos.iloc[i]\n",
    "        roi = objeto[\"ROI\"] #................. Compararemos su roi\n",
    "        for roi_t in rois_t: #................ con cada roi detectado en el nuevo frame\n",
    "            areaI = areaInterseccion(roi, roi_t) \n",
    "            if areaI / (roi[2] * roi[3]) > umbralRatioAr and areaI / (roi_t[2] * roi_t[3]) > umbralRatioAr: # Si el área de la intersección supera el umbral en ambos\n",
    "                agregados.append([objeto[\"ID\"], roi_t, t_frame, mseg]) #.... Agrega a un arreglo de \"filas a agregar\" al DataFrame objetos\n",
    "                rois_t.remove(roi_t) #...................................... Ya no tiene que analizar roi_t porque ya se le asignó id objeto\n",
    "    # -------- Pueden haber sobrado rois en rois_t, así que asumimos son nuevos objetos ---------------\n",
    "    n_ID = 0\n",
    "    if len(objetos) > 0:\n",
    "        n_ID = max(objetos[\"ID\"]) + 1 #.................. Empezar a enumerar a los objetos desde n_ID\n",
    "    for roi_t in rois_t:\n",
    "        agregados.append([n_ID, roi_t, t_frame, mseg])\n",
    "        n_ID += 1\n",
    "    return agregados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiarDF(dfObjetos):\n",
    "    idsObjetos = pd.unique(dfObjetos[\"ID\"])\n",
    "    for i in idsObjetos:\n",
    "        aux = dfObjetos[dfObjetos[\"ID\"] == i]\n",
    "        if len(aux) < 30 and len(aux) > 0:\n",
    "            aux = dfObjetos.index[dfObjetos[\"ID\"] == i].tolist()\n",
    "            dfObjetos = objetos.drop(aux)\n",
    "    return dfObjetos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Realización:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ROI</th>\n",
       "      <th>Frame</th>\n",
       "      <th>Segundo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(213, 233, 6, 4)</td>\n",
       "      <td>38</td>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>(213, 233, 6, 4)</td>\n",
       "      <td>39</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>(220, 234, 1, 1)</td>\n",
       "      <td>40</td>\n",
       "      <td>1.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>(215, 233, 4, 2)</td>\n",
       "      <td>40</td>\n",
       "      <td>1.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>(213, 233, 10, 4)</td>\n",
       "      <td>41</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                ROI  Frame  Segundo\n",
       "0   0   (213, 233, 6, 4)     38     1.30\n",
       "1   0   (213, 233, 6, 4)     39     1.33\n",
       "2   1   (220, 234, 1, 1)     40     1.37\n",
       "3   2   (215, 233, 4, 2)     40     1.37\n",
       "4   3  (213, 233, 10, 4)     41     1.40"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \" *Vxp \" significa \"Experimentar con los valores\"\n",
    "capture.open(best.url)\n",
    "_, A = capture.read() #.......... Frame \"Original\", se asume que en este no hay \"objetos\" en pantalla\n",
    "A = cv2.cvtColor(A,cv2.COLOR_RGB2GRAY)\n",
    "nH = int(A.shape[0] // 1.5)\n",
    "nW = int(A.shape[1] // 1.5)\n",
    "objetos = [] #................... Arreglo que se espera sea: [ [ [(x,y,w,h), frame, milisegundo], \n",
    "#................................                                [(x,y,w,h), frame, milisegundo],...] , [ [roi, frame, t], ... ]\n",
    "A = cv2.resize(A, (nW,nH)) #................ Baja la resolución del frame\n",
    "for i in range(N_Prueba): #................. No ocupa todo el video, por ahora solo frames de prueba\n",
    "    #print(\"============== FRAME %s ==============\"%i)\n",
    "    _, b = capture.read()\n",
    "    ms = capture.get(0) # Get los milisegundos\n",
    "    ms = round( ms/1000 ,2)\n",
    "    b = cv2.cvtColor(b,cv2.COLOR_RGB2GRAY)\n",
    "    b = cv2.resize(b, (nW,nH))\n",
    "    rois = roisDeFrame(A, b, 15, 80) # * Vxp, la dimensión del kernel debe ser impar\n",
    "    #print(\">> len(objetos): \", len(objetos))\n",
    "    #print(\">> ROIs crudos: \",len(rois))\n",
    "    #---- Pasar solo los objetos que aparecieron en el frame (i-1):\n",
    "    objetos_previos = []\n",
    "    if i > 0 and len(objetos) > 0:\n",
    "        objetos_previos = objetos[objetos[\"Frame\"] == i - 1]\n",
    "    nuevasFilas = asignarObjetos(objetos_previos,rois,i,ms,0.6) # * Vxp, umbral de ratio de area interseccion\n",
    "    #---- nuevasFilas está en el formato, pero \"objetos\" puede aún ser nulo, así que valida:\n",
    "    nuevasFilas = pd.DataFrame(data=nuevasFilas,columns=[\"ID\",\"ROI\",\"Frame\",\"Segundo\"])\n",
    "    if len(objetos) > 0:\n",
    "        objetos = objetos.append(nuevasFilas,ignore_index=True) # ... Si ya existen objetos, añade los nuevos\n",
    "    else:\n",
    "        objetos = nuevasFilas #...................................... Si nunca hubieron, ahora hay\n",
    "capture.release()\n",
    "print(len(pd.unique(objetos[\"ID\"])))\n",
    "objetos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "objetos = limpiarDF(objetos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148], dtype=int64)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficarRectDeObjetos(imagen, objetos):\n",
    "    for i in range(len(objetos)):\n",
    "        objeto = objetos.iloc[i]\n",
    "        (x,y,w,h) = objeto[\"ROI\"]\n",
    "        cv2.rectangle(imagen, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "        texto = \"Obj %s en %s ms\"%(objeto[\"ID\"],objeto[\"Segundo\"])\n",
    "        imagen = cv2.putText(imagen, texto, (x,y), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                   0.3, (180,255,0), 1, cv2.LINE_AA)\n",
    "    return imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "aux = None\n",
    "capture.open(best.url)\n",
    "while(True):\n",
    "    _, frame = capture.read()\n",
    "    frame = cv2.resize(frame, (nW,nH)) #.... TODO: pasar ROI a la resolución original :c\n",
    "    #arrROIs = objetos[objetos[\"Frame\"] == j][\"ROI\"].values\n",
    "    arrObjs = objetos[objetos[\"Frame\"] == j]\n",
    "    if len(arrObjs) > 0:\n",
    "        frame = graficarRectDeObjetos(frame, arrObjs)\n",
    "    cv2.imshow(\"Diferencia\",frame)\n",
    "    if j == 2:\n",
    "        aux = frame\n",
    "    j += 1\n",
    "    if(cv2.waitKey(20) & 0xFF == ord('q')):\n",
    "        break\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2_imshow(aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrayendo los rois como imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-144-23a5bb0086b4>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-144-23a5bb0086b4>\"\u001b[1;36m, line \u001b[1;32m13\u001b[0m\n\u001b[1;33m    for i in range(len(objs)):\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "Im_roi = []\n",
    "Frames = []\n",
    "def capturar_RoiIm(objs):\n",
    "    capture.open(best.url) #eso puede o no que sea cambiado\n",
    "    auxObjs = Objs.copy()\n",
    "    for f in range(N_Prueba): #corriendo por cada frame \n",
    "        i = 0\n",
    "        while(len(auxObjs) > 0):\n",
    "            7Kv#8Txd\n",
    "            x,y,an,la = objs.iloc[i][1]   #ancho, largo\n",
    "            if an < 50 or la < 50:\n",
    "                continue\n",
    "\n",
    "            iframe = objs.iloc[i][2]      #número del frame\n",
    "            capture.set(1,iframe) #1 porque es un flag, numero del frame que se quiere ubicar\n",
    "            _,frame = capture.read()\n",
    "            if frame is not None:\n",
    "                im = frame[x:x+an,y:y+la]\n",
    "            else:\n",
    "                print(iframe)\n",
    "                break \n",
    "            i += 1\n",
    "        \n",
    "\n",
    "        \n",
    "#         _, frame = capture.read()\n",
    "#         im = frame[1]\n",
    "\n",
    "    \n",
    "\n",
    "capturar_RoiIm(objetos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 1280)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Material adicional:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* OpenCV Python Tutorials. *Getting started with videos*. Recuperado de: https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html\n",
    "* OpenCV. *Reading and writing images and video* Recuperado de: https://docs.opencv.org/2.4/modules/highgui/doc/reading_and_writing_images_and_video.html#videocapture-get "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pH7A73FhJ51o"
   },
   "source": [
    "### Resultados y Discusión (6 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWS0I-GXJ57i"
   },
   "source": [
    "<font color='green'> Discuta los **varios resultados obtenidos** por la selección de **diversos parámetros seleccionados** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primera parte de nuestro método fue la detección de regiones de interés en dos frames distintos. Extraímos los contornos de la imagen de la diferencia de los dos frames. Dentro de este método, aplicamos el filtro de la mediana para disminuir el posible ruido en la imagen $D$ (Diferencia), y binarizamos a partir de un umbral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para probar los mejores valores en esta sección, tomamos dos frames del video:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frame 0: ![Frame 0](Informe_Recursos/Auto0.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frame X: ![Frame X](Informe_Recursos/AutoX.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, aplicamos nuestro método para detectar las ROIs del frame $X$. Esperamos tener dos regiones de interés: la mujer saliendo del carro y el auto en movimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ayudarnos con la métrica y análisis de resultados, definimos una función que retorne un arreglo de los errores paralelo a los valores obtenidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcError(esperado, arrObtenidos):\n",
    "    arrError = []\n",
    "    for obtenido in arrObtenidos:\n",
    "        arrError.append(abs(esperado - obtenido))\n",
    "    return arrError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queremos evaluar la función\n",
    "```\n",
    "roisDeFrame(f0, fn, dimKernelBlur, umbralDif)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Frame_Prue' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-a2b9869f5fde>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mroisDeFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFrame_Prueba_0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mFrame_Prue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Frame_Prue' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(150,255):\n",
    "    roisDeFrame(Frame_Prueba_0,Frame_Prue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jEyQ2THGJ6BA"
   },
   "source": [
    "### Conclusiones (2 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNOKEOoRJ6Ep"
   },
   "source": [
    "<font color='green'> Redacte, al menos, **5 conclusiones relevantes** referentes a como cubrió su objetivo y que le ayudó a optimizar sus resutlados. </font>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "PDI - Examen Final - 2020-2",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
